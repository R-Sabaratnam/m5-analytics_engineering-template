{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44535db6",
   "metadata": {},
   "source": [
    "#### Analytics Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f104eb",
   "metadata": {},
   "source": [
    "# Intro to Analytics Engineering / Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c5ef01",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258a5b7",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Project \"Weather vs Flights Data\" <br>üéØ Goal: Construct ELT data pipeline using python, pandas, more advanced SQL, SQLalchemy, and dbt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ecbcf",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c3ff4",
   "metadata": {},
   "source": [
    "In this week, you will learn how to connect to your database with Python and how to design and to automate a pipeline. Next week we could use the collected data for a Dashboard to visualize the results. \n",
    "\n",
    "The next days, you will work with a comprehensive real world API from https://dev.meteostat.net/api/. We will get access to historical weather records (daily and hourly) from basically everywhere around over the world. We will aim to obtain weather data for 3 airport locations: New York (JFK), Los Angeles (LAX), And Miami (MIA) from the last year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11de3e45",
   "metadata": {},
   "source": [
    "#### Milestones\n",
    "\n",
    "1. Access data from real world API using a python script\n",
    "\n",
    "2. Using SQLalchemy import raw data into postgres database \n",
    "\n",
    "3. Connect database to dbt cloud - which will be used to parse and prepare the data\n",
    "\n",
    "4. Clean prepare the data on dbt cloud using CTE and the power of dbt\n",
    "\n",
    "5. Answer questions with the data and save the answers in a data mart for your stakeholders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201b791",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce3d73",
   "metadata": {},
   "source": [
    "### What is the use of .env file in projects?    \n",
    "### How to store sensitive information like API keys or database credentials  in .env file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b64f6e4",
   "metadata": {},
   "source": [
    "### üîëüîëüîëüîë`.env` Files  üîëüîëüîëüîëüîë\n",
    "\n",
    "\n",
    " It's common for teams to maintain distinct \"environments\" for their codebase. These separate environments allow thorough testing before deploying changes to the production environment, where they interact with end-users. In scenarios involving multiple environments, developers often opt to use multiple .env files to store credentials. For instance, they might have one \n",
    " .env file containing database keys for development and another for production.\n",
    "\n",
    " This separation of code and credentials lower the risk of unauthorized individuals gaining access to sensitive data in the cloud.\n",
    "\n",
    "**.env** files are specifically designed to store credentials in a key-value format for the various services that the program utilizes. These files are intended to be stored locally and not shared in online code repositories, ensuring that sensitive information remains confidential. Each developer within a team typically manages one or more `.env` files, tailored for the specific environments they are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feed426",
   "metadata": {},
   "source": [
    "## Key uses and benefits of using a .env file in projects:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557ef3d5",
   "metadata": {},
   "source": [
    "- ***Centralized Configuration:*** The .env file stores all project configuration settings, like API keys and database connections, separately from the code, making management easier.\n",
    "\n",
    "- ***Environment Variables:*** It allows you to set environment variables that your application can use, promoting flexibility and separation of configuration from code.\n",
    "\n",
    "- ***Storing Sensitive Information:*** Sensitive data, such as passwords and access tokens, can be safely stored in the .env file, protecting them from exposure in the codebase.\n",
    "\n",
    "- ***Ease of Deployment***: Customizes settings for different environments (development, staging, production) without needing code changes.\n",
    "\n",
    "- ***Git Ignore:*** The .env file should be added to .gitignore to prevent it from being tracked by version control systems, protecting sensitive information.\n",
    "\n",
    "- ***Readability and Maintainability:*** Improves code readability and maintainability by keeping configuration settings organized and easy to update.\n",
    "\n",
    "- ***Security Best Practices:*** Keeps sensitive information out of version-controlled files, reducing the risk of accidental exposure and simplifying access control management.\n",
    "\n",
    "- ***Library Usage:*** Libraries like python-dotenv in Python projects can read the .env file and set environment variables, making them accessible in the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405f6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e25f6a3",
   "metadata": {},
   "source": [
    "#### Usage\n",
    "\n",
    "In this section, we‚Äôll walk through how to use a `.env` file in a basic python project.\n",
    "\n",
    "1. To begin, head to the root of your **week folder** and create an empty `.env` file containing credentials you‚Äôd like injected into your codebase. It may look something like this:\n",
    "\n",
    "```python\n",
    "POSTGRES_USER = 'saramaras'\n",
    "POSTGRES_PASS = 'OmNU2guAJkp3KwDE' # never add your password to a jupyter notebook!\n",
    "POSTGRES_HOST = 'data-analytics-course-2.c8g8r1deus2v.eu-central-1.rds.amazonaws.com'\n",
    "POSTGRES_PORT = '5432'\n",
    "POSTGRES_DB = 'postgres'\n",
    "POSTGRES_SCHEMA = 'sara_dont_touch'\n",
    "```\n",
    "\n",
    "2. Keep in mind that the `.env` file should NOT be uploaded to **github**. A file called `.env_example` could be uploaded in order to give an example of what the `.env` file should contain. Therefore the `.env` file should be always in your `.gitignore` file! (it should be there already)\n",
    "\n",
    "\n",
    "3. Now to inject the secrets into your project, you can use a popular module like dotenv; it will parse the `.env` file and make your secrets accessible within your codebase under the process object. Go ahead and install the module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fbff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fafdd5",
   "metadata": {},
   "source": [
    "4. Import the module at the top of the start script for your codebase:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb5a7e1",
   "metadata": {},
   "source": [
    "**First option:** `dotenv_values()` will only read the `.env` file and return a *temporary* dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting API and DB credentials\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values()\n",
    "pg_user = config['POSTGRES_USER']  # align the key label with your .env file !\n",
    "pg_host = config['POSTGRES_HOST']\n",
    "pg_port = config['POSTGRES_PORT']\n",
    "pg_db = config['POSTGRES_DB']\n",
    "#pg_schema = config['POSTGRES_SCHEMA']\n",
    "pg_pass = config['POSTGRES_PASS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9045fb",
   "metadata": {},
   "source": [
    "**Second option:** `load_dotenv()` : will actually load the key/values into your running os enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de38836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting API and DB credentials\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "# pg_host = os.getenv('POSTGRES_HOST') # align the key label with your .env file !\n",
    "# pg_user = os.getenv('POSTGRES_USER')  # align the key label with your .env file !\n",
    "# pg_host = os.getenv('POSTGRES_HOST')\n",
    "# pg_port = os.getenv('POSTGRES_PORT')\n",
    "# pg_db = os.getenv('POSTGRES_DB')\n",
    "# pg_schema = os.getenv('POSTGRES_SCHEMA')\n",
    "# pg_pass = os.getenv('POSTGRES_PASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886a4007",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_host"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6084b5a",
   "metadata": {},
   "source": [
    "Cool. We‚Äôve successfully added a `.env` file into your project with some secrets and accessed those secrets in your codebase. Additionally, when you push your code via git, your secrets will stay on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b179c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
